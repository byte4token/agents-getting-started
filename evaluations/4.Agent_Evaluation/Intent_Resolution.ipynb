{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Resolution Evaluator\n",
    "\n",
    "## Objective\n",
    "This sample demonstrates to how to use intent resolution evaluator on agent data. The supported input formats include:\n",
    "- simple data such as strings;\n",
    "- user-agent conversations in the form of list of agent messages. \n",
    "\n",
    "## Time\n",
    "\n",
    "You should expect to spend about 20 minutes running this notebook. \n",
    "\n",
    "## Before you begin\n",
    "For quality evaluation, you need to deploy a `gpt` model supporting JSON mode. We recommend a model `gpt-4o` or `gpt-4o-mini` for their strong reasoning capabilities.    \n",
    "\n",
    "### Prerequisite\n",
    "```bash\n",
    "pip install azure-ai-projects azure-identity azure-ai-evaluation\n",
    "```\n",
    "Set these environment variables with your own values:\n",
    "1) **PROJECT_CONNECTION_STRING** - The project connection string, as found in the overview page of your Azure AI Foundry project.\n",
    "2) **MODEL_DEPLOYMENT_NAME** - The deployment name of the model for this AI-assisted evaluator, as found under the \"Name\" column in the \"Models + endpoints\" tab in your Azure AI Foundry project.\n",
    "3) **AZURE_OPENAI_ENDPOINT** - Azure Open AI Endpoint to be used for evaluation.\n",
    "4) **AZURE_OPENAI_API_KEY** - Azure Open AI Key to be used for evaluation.\n",
    "5) **AZURE_OPENAI_API_VERSION** - Azure Open AI Api version to be used for evaluation.\n",
    "6) **AZURE_SUBSCRIPTION_ID** - Azure Subscription Id of Azure AI Project\n",
    "7) **PROJECT_NAME** - Azure AI Project Name\n",
    "8) **RESOURCE_GROUP_NAME** - Azure AI Project Resource Group Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Intent Resolution evaluator measures how well an agent has identified and resolved the user intent.\n",
    "The scoring is on a 1-5 integer scale and is as follows:\n",
    "\n",
    "  - Score 1: Response completely unrelated to user intent\n",
    "  - Score 2: Response minimally relates to user intent\n",
    "  - Score 3: Response partially addresses the user intent but lacks complete details\n",
    "  - Score 4: Response addresses the user intent with moderate accuracy but has minor inaccuracies or omissions\n",
    "  - Score 5: Response directly addresses the user intent and fully resolves it\n",
    "\n",
    "The evaluation requires the following inputs:\n",
    "\n",
    "  - Query    : The user query. Either a string with a user request or a list of messages with previous requests from the user and responses from the assistant, potentially including a system message.\n",
    "  - Response : The response to be evaluated. Either a string or a message with the response from the agent to the last user query.\n",
    "\n",
    "There is a third optional parameter:\n",
    "  - ToolDefinitions : The list of tool definitions the agent can call. This may be useful for the evaluator to better assess if the right tool was called to resolve a given intent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Intent Resolution Evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "from azure.ai.evaluation import IntentResolutionEvaluator\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Force load eval.env and override any existing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ[\"OAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"OAI_KEY\"],\n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"OAI_MODEL_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "\n",
    "intent_resolution_evaluator = IntentResolutionEvaluator(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating query and response as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversation history could not be parsed, falling back to original query: What are the opening hours of the Eiffel Tower?\n",
      "Empty agent response extracted, likely due to input schema change. Falling back to using the original response: Opening hours of the Eiffel Tower are 9:00 AM to 11:00 PM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent_resolution': 5.0,\n",
      " 'intent_resolution_reason': 'User wanted to know the opening hours of the '\n",
      "                             'Eiffel Tower. The agent provided a clear, '\n",
      "                             'accurate, and complete response, fully resolving '\n",
      "                             'the intent without any gaps or issues.',\n",
      " 'intent_resolution_result': 'pass',\n",
      " 'intent_resolution_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "# Success example. Intent is identified and understood and the response correctly resolves user intent\n",
    "result = intent_resolution_evaluator(\n",
    "    query=\"What are the opening hours of the Eiffel Tower?\",\n",
    "    response=\"Opening hours of the Eiffel Tower are 9:00 AM to 11:00 PM.\",\n",
    ")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversation history could not be parsed, falling back to original query: What is the opening hours of the Eiffel Tower?\n",
      "Empty agent response extracted, likely due to input schema change. Falling back to using the original response: Please check the official website for the up-to-date information on Eiffel Tower opening hours.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent_resolution': 2.0,\n",
      " 'intent_resolution_reason': 'User wanted the opening hours of the Eiffel '\n",
      "                             'Tower. Agent redirected them to the official '\n",
      "                             'website without providing the requested '\n",
      "                             'information directly, leaving the intent '\n",
      "                             'partially unresolved.',\n",
      " 'intent_resolution_result': 'fail',\n",
      " 'intent_resolution_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "# Failure example. Even though intent is correctly identified, the response does not resolve the user intent\n",
    "result = intent_resolution_evaluator(\n",
    "    query=\"What is the opening hours of the Eiffel Tower?\",\n",
    "    response=\"Please check the official website for the up-to-date information on Eiffel Tower opening hours.\",\n",
    ")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating query and response as list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent_resolution': 5.0,\n",
      " 'intent_resolution_reason': 'User wanted an update on the status of their '\n",
      "                             'last two orders. The agent provided accurate and '\n",
      "                             'complete details for both orders, including '\n",
      "                             'shipping and delivery updates, fully resolving '\n",
      "                             'the intent.',\n",
      " 'intent_resolution_result': 'pass',\n",
      " 'intent_resolution_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "query = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a friendly and helpful customer service agent.\"},\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:14:20Z\",\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Hi, I need help with the last 2 orders on my account #888. Could you please update me on their status?\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "response = [\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:14:30Z\",\n",
    "        \"run_id\": \"0\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"Hello! Let me quickly look up your account details.\"}],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:14:35Z\",\n",
    "        \"run_id\": \"0\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_call\",\n",
    "                \"tool_call_id\": \"tool_call_20250310_001\",\n",
    "                \"name\": \"get_orders\",\n",
    "                \"arguments\": {\"account_number\": \"888\"},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:14:40Z\",\n",
    "        \"run_id\": \"0\",\n",
    "        \"tool_call_id\": \"tool_call_20250310_001\",\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": [{\"type\": \"tool_result\", \"tool_result\": '[{ \"order_id\": \"123\" }, { \"order_id\": \"124\" }]'}],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:14:45Z\",\n",
    "        \"run_id\": \"0\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Thanks for your patience. I see two orders on your account. Let me fetch the details for both.\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:14:50Z\",\n",
    "        \"run_id\": \"0\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_call\",\n",
    "                \"tool_call_id\": \"tool_call_20250310_002\",\n",
    "                \"name\": \"get_order\",\n",
    "                \"arguments\": {\"order_id\": \"123\"},\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"tool_call\",\n",
    "                \"tool_call_id\": \"tool_call_20250310_003\",\n",
    "                \"name\": \"get_order\",\n",
    "                \"arguments\": {\"order_id\": \"124\"},\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:14:55Z\",\n",
    "        \"run_id\": \"0\",\n",
    "        \"tool_call_id\": \"tool_call_20250310_002\",\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_result\": '{ \"order\": { \"id\": \"123\", \"status\": \"shipped\", \"delivery_date\": \"2025-03-15\" } }',\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:15:00Z\",\n",
    "        \"run_id\": \"0\",\n",
    "        \"tool_call_id\": \"tool_call_20250310_003\",\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_result\": '{ \"order\": { \"id\": \"124\", \"status\": \"delayed\", \"expected_delivery\": \"2025-03-20\" } }',\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-14T06:15:05Z\",\n",
    "        \"run_id\": \"0\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"The order with ID 123 has been shipped and is expected to be delivered on March 15, 2025. However, the order with ID 124 is delayed and should now arrive by March 20, 2025. Is there anything else I can help you with?\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please note that the tool definitions are not strictly required, and that some of the tools below are not used in the example above and that is ok.\n",
    "# if context length is a concern you can remove the unused tool definitions or even the tool definitions altogether as the impact to the intent resolution evaluation is usual minimal.\n",
    "tool_definitions = [\n",
    "    {\n",
    "        \"name\": \"get_orders\",\n",
    "        \"description\": \"Get the list of orders for a given account number.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"account_number\": {\"type\": \"string\", \"description\": \"The account number to get the orders for.\"}\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_order\",\n",
    "        \"description\": \"Get the details of a specific order.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"order_id\": {\"type\": \"string\", \"description\": \"The order ID to get the details for.\"}},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"initiate_return\",\n",
    "        \"description\": \"Initiate the return process for an order.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"order_id\": {\"type\": \"string\", \"description\": \"The order ID for the return process.\"}},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"update_shipping_address\",\n",
    "        \"description\": \"Update the shipping address for a given account.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"account_number\": {\"type\": \"string\", \"description\": \"The account number to update.\"},\n",
    "                \"new_address\": {\"type\": \"string\", \"description\": \"The new shipping address.\"},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "result = intent_resolution_evaluator(\n",
    "    query=query,\n",
    "    response=response,\n",
    "    tool_definitions=tool_definitions,\n",
    ")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch evaluate and visualize results on Azure AI Foundry\n",
    "Batch evaluate to leverage asynchronous evaluation on a dataset. \n",
    "\n",
    "Optionally, you can go to AI Foundry URL for rich Azure AI Foundry data visualization. You can inspect the evaluation scores and reasoning to quickly identify bugs and issues of your agent to fix and improve. Make sure to authenticate to Azure using `az login` in your terminal before running this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Average execution time for completed lines: 1.24 seconds. Estimated time for incomplete lines: 4.96 seconds.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Average execution time for completed lines: 0.63 seconds. Estimated time for incomplete lines: 1.89 seconds.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Average execution time for completed lines: 0.43 seconds. Estimated time for incomplete lines: 0.86 seconds.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Average execution time for completed lines: 0.33 seconds. Estimated time for incomplete lines: 0.33 seconds.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-27 19:35:26 -0400    9524 execution.bulk     INFO     Average execution time for completed lines: 0.28 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"intent_resolution_20251027_233525_134907\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-27 23:35:25.134907+00:00\"\n",
      "Duration: \"0:00:02.031050\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"intent_resolution\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:02.031050\",\n",
      "        \"completed_lines\": 5,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "'AI Foundary URL: None'\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "\n",
    "# This sample files contains the evaluation data in JSONL format. Where each line is a run from agent.\n",
    "# This was saved using agent thread and converter.\n",
    "file_name = \"evaluation_data.jsonl\"\n",
    "\n",
    "response = evaluate(\n",
    "    azure_ai_project=os.environ.get(\"AIPROJECT_CONNECTION_STRING\"),\n",
    "    data=file_name,\n",
    "    evaluation_name=\"Intent Resolution Evaluation\",\n",
    "    evaluators={\n",
    "        \"intent_resolution\": intent_resolution_evaluator,\n",
    "    },\n",
    ")\n",
    "pprint(f'AI Foundary URL: {response.get(\"studio_url\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-evals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

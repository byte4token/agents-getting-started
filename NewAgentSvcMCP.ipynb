{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b40616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True) # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2c580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "from azure.ai.agents.models import MessageTextContent, ListSortOrder\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544b148b",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(unknown_parameter) Unknown parameter: 'tools[0].require_approval'.\nCode: unknown_parameter\nMessage: Unknown parameter: 'tools[0].require_approval'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m project_client = AIProjectClient(\n\u001b[32m      2\u001b[39m     endpoint=os.environ[\u001b[33m\"\u001b[39m\u001b[33mFOUNDRY_PROJECT_ENDPOINT\u001b[39m\u001b[33m\"\u001b[39m] ,\n\u001b[32m      3\u001b[39m     credential=DefaultAzureCredential()\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m project_client:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     agent = \u001b[43mproject_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCHAT_MODEL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy-mcp-agent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a helpful assistant. Use the tools provided to answer the user\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms questions. Be sure to cite your sources.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmcp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m\t\t        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mserver_label\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlang_graph_mcp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mserver_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://gitmcp.io/langchain-ai/langgraph\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrequire_approval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnever\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated agent, agent ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\sandbox\\agents-getting-started\\myenv2\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\sandbox\\agents-getting-started\\myenv2\\Lib\\site-packages\\azure\\ai\\agents\\_patch.py:322\u001b[39m, in \u001b[36mAgentsClient.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, toolset, temperature, top_p, response_format, metadata, content_type, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m     tools = toolset.definitions\n\u001b[32m    320\u001b[39m     tool_resources = toolset.resources\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m new_agent = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_agent\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\sandbox\\agents-getting-started\\myenv2\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\sandbox\\agents-getting-started\\myenv2\\Lib\\site-packages\\azure\\ai\\agents\\operations\\_operations.py:5329\u001b[39m, in \u001b[36m_AgentsClientOperationsMixin.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, temperature, top_p, response_format, metadata, **kwargs)\u001b[39m\n\u001b[32m   5327\u001b[39m     map_error(status_code=response.status_code, response=response, error_map=error_map)\n\u001b[32m   5328\u001b[39m     error = _failsafe_deserialize(_models.AgentV1Error, response.json())\n\u001b[32m-> \u001b[39m\u001b[32m5329\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response, model=error)\n\u001b[32m   5331\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[32m   5332\u001b[39m     deserialized = response.iter_bytes()\n",
      "\u001b[31mHttpResponseError\u001b[39m: (unknown_parameter) Unknown parameter: 'tools[0].require_approval'.\nCode: unknown_parameter\nMessage: Unknown parameter: 'tools[0].require_approval'."
     ]
    }
   ],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"FOUNDRY_PROJECT_ENDPOINT\"] ,\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=os.environ[\"CHAT_MODEL\"] , \n",
    "        name=\"my-mcp-agent\", \n",
    "        instructions=\"You are a helpful assistant. Use the tools provided to answer the user's questions. Be sure to cite your sources.\",\n",
    "        tools= [\n",
    "            {\n",
    "                \"type\": \"mcp\",\n",
    "\t\t        \"server_label\": \"lang_graph_mcp\",\n",
    "                \"server_url\": \"https://gitmcp.io/langchain-ai/langgraph\",\n",
    "                \"require_approval\": \"never\"\n",
    "            }\n",
    "        ],\n",
    "        tool_resources=None\n",
    "    )\n",
    "    print(f\"Created agent, agent ID: {agent.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id, role=\"user\", content=\"<a question for your MCP server>\",\n",
    ")\n",
    "print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import CodeInterpreterTool\n",
    "\n",
    "# Create an Azure AI Client from an endpoint, copied from your Azure AI Foundry project.\n",
    "# You need to login to Azure subscription via Azure CLI and set the environment variables\n",
    "project_endpoint = os.environ[\"FOUNDRY_PROJECT_ENDPOINT\"]  # Ensure the PROJECT_ENDPOINT environment variable is set\n",
    "\n",
    "# Create an AIProjectClient instance\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),  # Use Azure Default Credential for authentication\n",
    ")\n",
    "\n",
    "code_interpreter = CodeInterpreterTool()\n",
    "with project_client:\n",
    "    # Create an agent with the Bing Grounding tool\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=os.environ[\"FOUNDRY_MODEL_DEPLOYMENT_NAME\"],  # Model deployment name\n",
    "        name=\"my-agent\",  # Name of the agent\n",
    "        instructions=\"You are a helpful agent\",  # Instructions for the agent\n",
    "        tools=code_interpreter.definitions,  # Attach the tool\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread for communication\n",
    "    thread = project_client.agents.threads.create()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a message to the thread\n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",  # Role of the message sender\n",
    "        content=\"What is the weather in Seattle today?\",  # Message content\n",
    "    )\n",
    "    print(f\"Created message, ID: {message['id']}\")\n",
    "    \n",
    "    # Create and process an agent run\n",
    "    run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "    \n",
    "    # Check if the run failed\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    \n",
    "    # Fetch and log all messages\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for message in messages:\n",
    "        print(f\"Role: {message.role}, Content: {message.content}\")\n",
    "    \n",
    "    # Delete the agent when done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from typing import Optional\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.agents.models import DeepResearchTool, MessageRole, ThreadMessage\n",
    "\n",
    "\n",
    "def fetch_and_print_new_agent_response(\n",
    "    thread_id: str,\n",
    "    agents_client: AgentsClient,\n",
    "    last_message_id: Optional[str] = None,\n",
    ") -> Optional[str]:\n",
    "    response = agents_client.messages.get_last_message_by_role(\n",
    "        thread_id=thread_id,\n",
    "        role=MessageRole.AGENT,\n",
    "    )\n",
    "    if not response or response.id == last_message_id:\n",
    "        return last_message_id  # No new content\n",
    "\n",
    "    print(\"\\nAgent response:\")\n",
    "    print(\"\\n\".join(t.text.value for t in response.text_messages))\n",
    "\n",
    "    for ann in response.url_citation_annotations:\n",
    "        print(f\"URL Citation: [{ann.url_citation.title}]({ann.url_citation.url})\")\n",
    "\n",
    "    return response.id\n",
    "\n",
    "\n",
    "def create_research_summary(\n",
    "        message : ThreadMessage,\n",
    "        filepath: str = \"research_summary.md\"\n",
    ") -> None:\n",
    "    if not message:\n",
    "        print(\"No message content provided, cannot create research summary.\")\n",
    "        return\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as fp:\n",
    "        # Write text summary\n",
    "        text_summary = \"\\n\\n\".join([t.text.value.strip() for t in message.text_messages])\n",
    "        fp.write(text_summary)\n",
    "\n",
    "        # Write unique URL citations, if present\n",
    "        if message.url_citation_annotations:\n",
    "            fp.write(\"\\n\\n## References\\n\")\n",
    "            seen_urls = set()\n",
    "            for ann in message.url_citation_annotations:\n",
    "                url = ann.url_citation.url\n",
    "                title = ann.url_citation.title or url\n",
    "                if url not in seen_urls:\n",
    "                    fp.write(f\"- [{title}]({url})\\n\")\n",
    "                    seen_urls.add(url)\n",
    "\n",
    "    print(f\"Research summary written to '{filepath}'.\")\n",
    "\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"FOUNDRY_PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "conn_id = project_client.connections.get(name=os.environ[\"BING_RESOURCE_NAME\"]).id\n",
    "\n",
    "\n",
    "# Initialize a Deep Research tool with Bing Connection ID and Deep Research model deployment name\n",
    "deep_research_tool = DeepResearchTool(\n",
    "    bing_grounding_connection_id=conn_id,\n",
    "    deep_research_model=os.environ[\"DEEP_RESEARCH_MODEL_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "\n",
    "# Create Agent with the Deep Research tool and process Agent run\n",
    "with project_client:\n",
    "\n",
    "    with project_client.agents as agents_client:\n",
    "\n",
    "        # Create a new agent that has the Deep Research tool attached.\n",
    "        # NOTE: To add Deep Research to an existing agent, fetch it with `get_agent(agent_id)` and then,\n",
    "        # update the agent with the Deep Research tool.\n",
    "        agent = agents_client.create_agent(\n",
    "            model=os.environ[\"FOUNDRY_MODEL_DEPLOYMENT_NAME\"],\n",
    "            name=\"my-agent\",\n",
    "            instructions=\"You are a helpful Agent that assists in researching scientific topics.\",\n",
    "            tools=deep_research_tool.definitions,\n",
    "        )\n",
    "\n",
    "        # [END create_agent_with_deep_research_tool]\n",
    "        print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "        # Create thread for communication\n",
    "        thread = agents_client.threads.create()\n",
    "        print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "        # Create message to thread\n",
    "        message = agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=(\n",
    "                \"Give me the latest research on model hyperparameter tunning over the last year.\"\n",
    "            ),\n",
    "        )\n",
    "        print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "        print(f\"Start processing the message... this may take a few minutes to finish. Be patient!\")\n",
    "        # Poll the run as long as run status is queued or in progress\n",
    "        run = agents_client.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "        last_message_id = None\n",
    "        while run.status in (\"queued\", \"in_progress\"):\n",
    "            time.sleep(1)\n",
    "            run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "            last_message_id = fetch_and_print_new_agent_response(\n",
    "                thread_id=thread.id,\n",
    "                agents_client=agents_client,\n",
    "                last_message_id=last_message_id,\n",
    "            )\n",
    "            print(f\"Run status: {run.status}\")\n",
    "\n",
    "        print(f\"Run finished with status: {run.status}, ID: {run.id}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # Fetch the final message from the agent in the thread and create a research summary\n",
    "        final_message = agents_client.messages.get_last_message_by_role(\n",
    "            thread_id=thread.id, role=MessageRole.AGENT\n",
    "        )\n",
    "        if final_message:\n",
    "            create_research_summary(final_message)\n",
    "\n",
    "        # Clean-up and delete the agent once the run is finished.\n",
    "        # NOTE: Comment out this line if you plan to reuse the agent later.\n",
    "        #agents_client.delete_agent(agent.id)\n",
    "        #print(\"Deleted agent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

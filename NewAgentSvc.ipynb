{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b40616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True) # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1614b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_3KUaEjETcX9BbdrZndTorUl5\n",
      "Created thread, ID: thread_w3qRFCYgqEzb5P6C9RpNMiho\n",
      "Created message, ID: msg_D3V8RDCmyM0DHoj2QftlaKYz\n",
      "Run finished with status: RunStatus.FAILED\n",
      "Run failed: {'code': 'invalid_engine_error', 'message': 'Failed to resolve model info for: gpt4turbo'}\n",
      "Role: MessageRole.USER, Content: [{'type': 'text', 'text': {'value': 'What is the weather in Seattle today?', 'annotations': []}}]\n",
      "Deleted agent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import CodeInterpreterTool\n",
    "\n",
    "# Create an Azure AI Client from an endpoint, copied from your Azure AI Foundry project.\n",
    "# You need to login to Azure subscription via Azure CLI and set the environment variables\n",
    "project_endpoint = os.environ[\"FOUNDRY_PROJECT_ENDPOINT\"]  # Ensure the PROJECT_ENDPOINT environment variable is set\n",
    "\n",
    "# Create an AIProjectClient instance\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),  # Use Azure Default Credential for authentication\n",
    ")\n",
    "\n",
    "code_interpreter = CodeInterpreterTool()\n",
    "with project_client:\n",
    "    # Create an agent with the Bing Grounding tool\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=os.environ[\"FOUNDRY_MODEL_DEPLOYMENT_NAME\"],  # Model deployment name\n",
    "        name=\"my-agent\",  # Name of the agent\n",
    "        instructions=\"You are a helpful agent\",  # Instructions for the agent\n",
    "        tools=code_interpreter.definitions,  # Attach the tool\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread for communication\n",
    "    thread = project_client.agents.threads.create()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a message to the thread\n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",  # Role of the message sender\n",
    "        content=\"What is the weather in Seattle today?\",  # Message content\n",
    "    )\n",
    "    print(f\"Created message, ID: {message['id']}\")\n",
    "    \n",
    "    # Create and process an agent run\n",
    "    run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "    \n",
    "    # Check if the run failed\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    \n",
    "    # Fetch and log all messages\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for message in messages:\n",
    "        print(f\"Role: {message.role}, Content: {message.content}\")\n",
    "    \n",
    "    # Delete the agent when done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_CvXDREyWi3fimsULaaVMUnIQ\n",
      "Created thread, ID: thread_3vXD7TyTQqeBanTtUHxXbUvE\n",
      "Created message, ID: msg_5EaXgQmpuS7KXrTcD7OF5UxB\n",
      "Start processing the message... this may take a few minutes to finish. Be patient!\n",
      "\n",
      "Agent response:\n",
      "\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n",
      "Run finished with status: RunStatus.COMPLETED, ID: run_liDHO2s1wGmx21Jdk3UTUwmJ\n",
      "Research summary written to 'research_summary.md'.\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from typing import Optional\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.agents.models import DeepResearchTool, MessageRole, ThreadMessage\n",
    "\n",
    "\n",
    "def fetch_and_print_new_agent_response(\n",
    "    thread_id: str,\n",
    "    agents_client: AgentsClient,\n",
    "    last_message_id: Optional[str] = None,\n",
    ") -> Optional[str]:\n",
    "    response = agents_client.messages.get_last_message_by_role(\n",
    "        thread_id=thread_id,\n",
    "        role=MessageRole.AGENT,\n",
    "    )\n",
    "    if not response or response.id == last_message_id:\n",
    "        return last_message_id  # No new content\n",
    "\n",
    "    print(\"\\nAgent response:\")\n",
    "    print(\"\\n\".join(t.text.value for t in response.text_messages))\n",
    "\n",
    "    for ann in response.url_citation_annotations:\n",
    "        print(f\"URL Citation: [{ann.url_citation.title}]({ann.url_citation.url})\")\n",
    "\n",
    "    return response.id\n",
    "\n",
    "\n",
    "def create_research_summary(\n",
    "        message : ThreadMessage,\n",
    "        filepath: str = \"research_summary.md\"\n",
    ") -> None:\n",
    "    if not message:\n",
    "        print(\"No message content provided, cannot create research summary.\")\n",
    "        return\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as fp:\n",
    "        # Write text summary\n",
    "        text_summary = \"\\n\\n\".join([t.text.value.strip() for t in message.text_messages])\n",
    "        fp.write(text_summary)\n",
    "\n",
    "        # Write unique URL citations, if present\n",
    "        if message.url_citation_annotations:\n",
    "            fp.write(\"\\n\\n## References\\n\")\n",
    "            seen_urls = set()\n",
    "            for ann in message.url_citation_annotations:\n",
    "                url = ann.url_citation.url\n",
    "                title = ann.url_citation.title or url\n",
    "                if url not in seen_urls:\n",
    "                    fp.write(f\"- [{title}]({url})\\n\")\n",
    "                    seen_urls.add(url)\n",
    "\n",
    "    print(f\"Research summary written to '{filepath}'.\")\n",
    "\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"FOUNDRY_PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "conn_id = project_client.connections.get(name=os.environ[\"BING_CONNECTION_NAME\"]).id\n",
    "\n",
    "\n",
    "# Initialize a Deep Research tool with Bing Connection ID and Deep Research model deployment name\n",
    "deep_research_tool = DeepResearchTool(\n",
    "    bing_grounding_connection_id=conn_id,\n",
    "    deep_research_model=os.environ[\"DEEP_RESEARCH_MODEL_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "\n",
    "# Create Agent with the Deep Research tool and process Agent run\n",
    "with project_client:\n",
    "\n",
    "    with project_client.agents as agents_client:\n",
    "\n",
    "        # Create a new agent that has the Deep Research tool attached.\n",
    "        # NOTE: To add Deep Research to an existing agent, fetch it with `get_agent(agent_id)` and then,\n",
    "        # update the agent with the Deep Research tool.\n",
    "\n",
    "        agent = agents_client.get_agent(agent_id=\"asst_CvXDREyWi3fimsULaaVMUnIQ\")\n",
    "\n",
    "        # agent = agents_client.create_agent(\n",
    "        #     model=os.environ[\"FOUNDRY_MODEL_DEPLOYMENT_NAME\"],\n",
    "        #     name=\"my-agent\",\n",
    "        #     instructions=\"You are a helpful Agent that assists in researching scientific topics.\",\n",
    "        #     tools=deep_research_tool.definitions,\n",
    "        # )\n",
    "\n",
    "        # [END create_agent_with_deep_research_tool]\n",
    "        print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "        # Create thread for communication\n",
    "        thread = agents_client.threads.create()\n",
    "        print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "        # Create message to thread\n",
    "        message = agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=(\n",
    "                \"Give me the latest research on model hyperparameter tunning of deep neural networks over the last year.\"\n",
    "            ),\n",
    "        )\n",
    "        print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "        print(f\"Start processing the message... this may take a few minutes to finish. Be patient!\")\n",
    "        # Poll the run as long as run status is queued or in progress\n",
    "        run = agents_client.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "        last_message_id = None\n",
    "        while run.status in (\"queued\", \"in_progress\"):\n",
    "            time.sleep(1)\n",
    "            run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "            last_message_id = fetch_and_print_new_agent_response(\n",
    "                thread_id=thread.id,\n",
    "                agents_client=agents_client,\n",
    "                last_message_id=last_message_id,\n",
    "            )\n",
    "            print(f\"Run status: {run.status}\")\n",
    "\n",
    "        print(f\"Run finished with status: {run.status}, ID: {run.id}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # Fetch the final message from the agent in the thread and create a research summary\n",
    "        final_message = agents_client.messages.get_last_message_by_role(\n",
    "            thread_id=thread.id, role=MessageRole.AGENT\n",
    "        )\n",
    "        if final_message:\n",
    "            create_research_summary(final_message)\n",
    "\n",
    "        # Clean-up and delete the agent once the run is finished.\n",
    "        # NOTE: Comment out this line if you plan to reuse the agent later.\n",
    "        #agents_client.delete_agent(agent.id)\n",
    "        #print(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cea62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from typing import Optional\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.agents.models import DeepResearchTool, MessageRole, ThreadMessage\n",
    "\n",
    "\n",
    "def fetch_and_print_new_agent_response(\n",
    "    thread_id: str,\n",
    "    agents_client: AgentsClient,\n",
    "    last_message_id: Optional[str] = None,\n",
    ") -> Optional[str]:\n",
    "    response = agents_client.messages.get_last_message_by_role(\n",
    "        thread_id=thread_id,\n",
    "        role=MessageRole.AGENT,\n",
    "    )\n",
    "    if not response or response.id == last_message_id:\n",
    "        return last_message_id  # No new content\n",
    "\n",
    "    print(\"\\nAgent response:\")\n",
    "    print(\"\\n\".join(t.text.value for t in response.text_messages))\n",
    "\n",
    "    for ann in response.url_citation_annotations:\n",
    "        print(f\"URL Citation: [{ann.url_citation.title}]({ann.url_citation.url})\")\n",
    "\n",
    "    return response.id\n",
    "\n",
    "\n",
    "def create_research_summary(\n",
    "        message : ThreadMessage,\n",
    "        filepath: str = \"research_summary.md\"\n",
    ") -> None:\n",
    "    if not message:\n",
    "        print(\"No message content provided, cannot create research summary.\")\n",
    "        return\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as fp:\n",
    "        # Write text summary\n",
    "        text_summary = \"\\n\\n\".join([t.text.value.strip() for t in message.text_messages])\n",
    "        fp.write(text_summary)\n",
    "\n",
    "        # Write unique URL citations, if present\n",
    "        if message.url_citation_annotations:\n",
    "            fp.write(\"\\n\\n## References\\n\")\n",
    "            seen_urls = set()\n",
    "            for ann in message.url_citation_annotations:\n",
    "                url = ann.url_citation.url\n",
    "                title = ann.url_citation.title or url\n",
    "                if url not in seen_urls:\n",
    "                    fp.write(f\"- [{title}]({url})\\n\")\n",
    "                    seen_urls.add(url)\n",
    "\n",
    "    print(f\"Research summary written to '{filepath}'.\")\n",
    "\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"FOUNDRY_PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "conn_id = project_client.connections.get(name=os.environ[\"BING_CONNECTION_NAME\"]).id\n",
    "\n",
    "\n",
    "# Initialize a Deep Research tool with Bing Connection ID and Deep Research model deployment name\n",
    "deep_research_tool = DeepResearchTool(\n",
    "    bing_grounding_connection_id=conn_id,\n",
    "    deep_research_model=os.environ[\"DEEP_RESEARCH_MODEL_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "\n",
    "# Create Agent with the Deep Research tool and process Agent run\n",
    "with project_client:\n",
    "\n",
    "    with project_client.agents as agents_client:\n",
    "\n",
    "        # Create a new agent that has the Deep Research tool attached.\n",
    "        # NOTE: To add Deep Research to an existing agent, fetch it with `get_agent(agent_id)` and then,\n",
    "        # update the agent with the Deep Research tool.\n",
    "\n",
    "        #agent = agents_client.get_agent(agent_id=\"asst_CvXDREyWi3fimsULaaVMUnIQ\")\n",
    "\n",
    "        agent = agents_client.create_agent(\n",
    "            model=os.environ[\"FOUNDRY_MODEL_DEPLOYMENT_NAME\"],\n",
    "            name=\"my-agent\",\n",
    "            instructions=\"You are a helpful Agent that assists in researching scientific topics.\",\n",
    "            tools=deep_research_tool.definitions,\n",
    "        )\n",
    "\n",
    "        # [END create_agent_with_deep_research_tool]\n",
    "        print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "        # Create thread for communication\n",
    "        thread = agents_client.threads.create()\n",
    "        print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "        # Create message to thread\n",
    "        message = agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=(\n",
    "                \"Give me the latest research on model hyperparameter tunning of deep neural networks over the last year.\"\n",
    "            ),\n",
    "        )\n",
    "        print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "        print(f\"Start processing the message... this may take a few minutes to finish. Be patient!\")\n",
    "        # Poll the run as long as run status is queued or in progress\n",
    "        run = agents_client.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "        last_message_id = None\n",
    "        while run.status in (\"queued\", \"in_progress\"):\n",
    "            time.sleep(1)\n",
    "            run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "            last_message_id = fetch_and_print_new_agent_response(\n",
    "                thread_id=thread.id,\n",
    "                agents_client=agents_client,\n",
    "                last_message_id=last_message_id,\n",
    "            )\n",
    "            print(f\"Run status: {run.status}\")\n",
    "\n",
    "        print(f\"Run finished with status: {run.status}, ID: {run.id}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # Fetch the final message from the agent in the thread and create a research summary\n",
    "        final_message = agents_client.messages.get_last_message_by_role(\n",
    "            thread_id=thread.id, role=MessageRole.AGENT\n",
    "        )\n",
    "        if final_message:\n",
    "            create_research_summary(final_message)\n",
    "\n",
    "        # Clean-up and delete the agent once the run is finished.\n",
    "        # NOTE: Comment out this line if you plan to reuse the agent later.\n",
    "        #agents_client.delete_agent(agent.id)\n",
    "        #print(\"Deleted agent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
